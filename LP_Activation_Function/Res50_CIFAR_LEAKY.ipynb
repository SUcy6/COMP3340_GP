{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install medpy\n",
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchio as tio\n",
    "from torchio import AFFINE, DATA\n",
    "import torchio\n",
    "from torchio import ScalarImage, LabelMap, Subject, SubjectsDataset, Queue\n",
    "from torchio.data import UniformSampler\n",
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomAffine,\n",
    "    RandomElasticDeformation,\n",
    "    RandomNoise,\n",
    "    RandomMotion,\n",
    "    RandomBiasField,\n",
    "    RescaleIntensity,\n",
    "    Resample,\n",
    "    ToCanonical,\n",
    "    ZNormalization,\n",
    "    CropOrPad,\n",
    "RandomSpike,\n",
    "RandomBlur,\n",
    "RandomSwap,\n",
    "    HistogramStandardization,\n",
    "    OneOf,\n",
    "    Clamp,\n",
    "    Compose,\n",
    "    RandomGhosting,\n",
    ")\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from os.path import dirname, join, basename, isfile\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use CIFAR-10 dataset for training and CIFAR-10-C dataset for testing\n",
    "# Get CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "]))\n",
    "\n",
    "# Get CIFAR-10-C dataset which includes diffrent types of corruptions\n",
    "#!wget https://zenodo.org/record/2535967/files/CIFAR-10-C.tar\n",
    "#!tar -xvf CIFAR-10-C.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=True, data_name = None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.images_path = torch.tensor(np.load(os.path.join(data, data_name + \".npy\")))\n",
    "        self.images_class = torch.tensor(np.load(os.path.join(label,\"labels.npy\")))\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.images_path.shape[0] #return length\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        img = self.images_path[index, :, :]  # read every npy\n",
    "        img = img[:,:,0] # drop the final dim\n",
    "        label = self.images_class[index]  # read every npy\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = torch.Tensor(img)\n",
    "        img = torch.cat([img, img, img], dim=0)\n",
    "        label = label.type(torch.long)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label  # return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformer for the test dataset\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = int(0.2 * len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ResNet50 model with or without pretrained weights\n",
    "# Change all Relu functions to LeakyRelu\n",
    "def get_model(pretrain):\n",
    "    if pretrain == 1:\n",
    "        model = torchvision.models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "    else:\n",
    "        model = torchvision.models.resnet50(weights=None)\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            model._modules[name] = nn.LeakyReLU(inplace=True)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.Linear(1024, 10),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function and return loss\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return loss.item()\n",
    "\n",
    "# Define the validation function and return loss\n",
    "def validate(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            valid_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    return valid_loss\n",
    "\n",
    "# Define the testing function and return accuracy\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "def get_optimizer(model, lr):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "# Define the training process\n",
    "def train_process(model, device, train_loader, valid_loader, optimizer, epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_losses.append(train(model, device, train_loader, optimizer, epoch))\n",
    "        valid_losses.append(validate(model, device, valid_loader))\n",
    "    return train_losses, valid_losses\n",
    "\n",
    "# Define the testing process\n",
    "def test_process(model, device, test_loader):\n",
    "    test_acc = test(model, device, test_loader)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Define the device\n",
    "#device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size used for model training\n",
    "batch_size = 16\n",
    "# Define the names for data\n",
    "data_names = ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 9.746256\n",
      "Train Epoch: 1 [1600/40000 (4%)]\tLoss: 1.385909\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer \u001b[39m=\u001b[39m get_optimizer(model, learnR)\n\u001b[0;32m---> 14\u001b[0m train_losses, valid_losses \u001b[39m=\u001b[39m train_process(model, device, train_loader, val_loader, optimizer, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Plot the training loss given batch size = 16 and learning rate = 0.001 and leaky_relu\u001b[39;00m\n\u001b[1;32m     18\u001b[0m axs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mplot(train_losses)\n",
      "Cell \u001b[0;32mIn [28], line 11\u001b[0m, in \u001b[0;36mtrain_process\u001b[0;34m(model, device, train_loader, valid_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m valid_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train(model, device, train_loader, optimizer, epoch))\n\u001b[1;32m     12\u001b[0m     valid_losses\u001b[39m.\u001b[39mappend(validate(model, device, valid_loader))\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m train_losses, valid_losses\n",
      "Cell \u001b[0;32mIn [27], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m      9\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/models/resnet.py:151\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m    150\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n\u001b[0;32m--> 151\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn2(out)\n\u001b[1;32m    152\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m    154\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(out)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    146\u001b[0m     \u001b[39m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_batches_tracked\u001b[39m.\u001b[39;49madd_(\u001b[39m1\u001b[39;49m)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    150\u001b[0m             exponential_average_factor \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Empty the GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start training and testing with batchsize = 16 and learning rate = 0.001 and leaky_relu\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "learnR = 0.001\n",
    "test_accs = []\n",
    "i = 0\n",
    "model = get_model(1)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "model = model.to(device)\n",
    "optimizer = get_optimizer(model, learnR)\n",
    "train_losses, valid_losses = train_process(model, device, train_loader, val_loader, optimizer, 60)\n",
    "\n",
    "# Plot the training loss given batch size = 16 and learning rate = 0.001 and leaky_relu\n",
    "axs[0].plot(train_losses)\n",
    "axs[0].set_title('Training loss, given batch_size=16, learning_rate=0.001, leaky_relu')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "\n",
    "# Plot the validation loss given batch size = 16 and learning rate = 0.001 and leaky_relu\n",
    "axs[1].plot(valid_losses)\n",
    "axs[1].set_title('Validation loss, given batch_size=16, learning_rate=0.001, leaky_relu')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Loss')\n",
    "\n",
    "# Change the train_losses, valid_losses, test_losses, test_accs as different pandas dataframes\n",
    "train_lossespd = pd.DataFrame(train_losses)\n",
    "valid_lossespd = pd.DataFrame(valid_losses)\n",
    "\n",
    "# Save the dataframes as csv files\n",
    "train_lossespd.to_csv('train_losses.csv')\n",
    "valid_lossespd.to_csv('valid_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy and losses for different test data\n",
    "test_accs = []\n",
    "test_losses = []\n",
    "for data_name in data_names:\n",
    "    dataset = testDataset(data=\"./CIFAR-10-C\", label=\"./CIFAR-10-C\", transform=val_transformer, data_name= data_name)\n",
    "    # Get the last 10000 images as test data\n",
    "    lenth_of_dataset = len(dataset)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, range(lenth_of_dataset - 10000, lenth_of_dataset))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_acc, test_loss = test_process(model, device, test_loader)\n",
    "    test_accs.append(test_acc)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "# Plot the test accuracy for different test data\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar(data_names, test_accs)\n",
    "plt.title('Test accuracy for different test data')\n",
    "plt.xlabel('Test data')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Plot the test loss for different test data\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar(data_names, test_losses)\n",
    "plt.title('Test loss for different test data')\n",
    "plt.xlabel('Test data')\n",
    "plt.ylabel('Test loss')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Change the results as a pandas dataframe\n",
    "test_accspd = pd.DataFrame(test_accs, index=data_names)\n",
    "test_lossspd = pd.DataFrame(test_losses, index=data_names)\n",
    "\n",
    "# Save the dataframe as a csv file\n",
    "test_accspd.to_csv('test_accs.csv')\n",
    "test_lossspd.to_csv('test_losses.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
